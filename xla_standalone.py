import torch
import transcript_data
import tcn
import time
import torch.nn.functional as F
import numpy as np

import os 
import transcript_data
import time
import torch
import torch.nn as nn
from torch.nn.utils import weight_norm
import torch.nn.functional as F
from pathlib import Path
import importlib
import spliceAI

import torch_xla.core.xla_model as xm
import torch_xla.debug.metrics as met
import torch_xla.core.xla_model as xm
import torch_xla.distributed.parallel_loader as pl
import torch_xla.distributed.xla_multiprocessing as xmp

import torch_xla

def _train_update(step, loss, tracker, epoch):
    print(f'epoch: {epoch}, step: {step}, loss: {loss}, rate: {tracker.rate()}')

def one_epoch(model, dataloader, optimizer = None, device = "cpu", max_batches = None):
    rf = model.receptive_field
    
    train = not optimizer is None
    start_time = time.time()
    last_log_time = time.time()
    torch.set_grad_enabled(train)
    model.train() if train else model.eval()

    metrics = []
    
    batch_counter = 0
    for ((is_exon, lengths_), (one_hot, lengths), weights) in dataloader: 

        metrics.append({})
        
        #met.mark_step()

        if train: 
            optimizer.zero_grad()

        # convert to B x C x T (CNN) from B x T x C (RNN/transformer)
        # these are generated by rnn.pad_sequence internally
        one_hot = one_hot.permute(0, 2, 1) 
        is_exon = is_exon.permute(0, 2, 1)
    
        mask = is_exon.isnan() # record what is truly missing in is_exon (because of short genes)
    
        B,C,T = is_exon.shape # batch, channels, length

        # TODO: handle multiple meta channels (need to think carefully about joint masking)
        meta = torch.zeros( B, 2, T + rf * 2, device = "cpu")  # one hot, zero for missing
        meta[:, 0, rf:-rf] = is_exon[:,0,:]
        meta[:, 1, rf:-rf] = (1.-is_exon[:,0,:])
        
        mytime = time.time()

        one_hot_masked = one_hot.clone().detach().cpu()

        # this edits one_hot_masked inplace
        seq_mask = transcript_data.get_mask(B, T, one_hot_masked, min_span = 1, max_span = 10, mask_same = False)

        one_hot_masked = one_hot_masked.to(device)
        seq_mask = seq_mask.to(device)

        print("Mask time", time.time() - mytime)
    
        x = torch.concat( (meta, one_hot_masked), 1)
        
        output = model(x.nan_to_num()) # spliceAI uses conv which want B x C x T
                
        loss = tcn.my_bce_loss(seq_mask, mask, output, one_hot[:, :, rf:-rf]) 
    
        assert(not loss.isnan().item())

        if train:
            loss.backward()
            #optimizer.step()
            xm.optimizer_step(self.optimizer) # run_optimizer just does this 

        metrics[-1][ "loss" ] = loss.item()
        metrics[-1][ "time" ] = time.time() - start_time

        if (time.time() - last_log_time) > 60.0: 
            print("%i" % batch_counter, end = '\r')
            last_log_time = time.time()

        batch_counter += 1

        if (not max_batches is None) and (batch_counter >= max_batches): break

        xm.add_step_closure(_train_update, args=(step, loss, tracker, epoch)) # TODO: just do this every few steps
    
    keys = list(metrics[0].keys())
    prefix = "train_" if train else "test_"
    return {prefix+key: np.mean([d[key] for d in metrics]) for key in keys}

def _mp_fn(index):

    device = xm.xla_device() # == torch_xla.device()
    
    get_gene = transcript_data.get_generator(
        os.path.expanduser("hg38.fa.gz"), 
        "gencode.v24.annotation.gtf.gz",
        "ENCFF191YXW.tsv.gz") # neural cell polyA RNA-seq
    
    model = spliceAI.SpliceAI_10k(in_channels = 6, out_channels = 4, n_embed = 64).to(device)
    
    train_chroms = ["chr%i" % i for i in range(2,23)] + ["chrX"]
    test_chroms = ["chr1"]
    
    # batch_size = 10. Cadaceus done 2^20 ~ 1M tokens per batch. So og is 10x smaller
    # we pass cpu as the device since MpDeviceLoader handles the transfer to the TPU
    train_dataloader = transcript_data.get_dataloader(get_gene, train_chroms, receptive_field = 5000, batch_size = 20, device = "cpu", max_len = 10000 )
    train_device_loader = pl.MpDeviceLoader(train_dataloader, device)
    
    # could use bigger batch here but want to be consistent with mamba
    test_dataloader = transcript_data.get_dataloader(get_gene, test_chroms, receptive_field = 5000, batch_size = 1, device = "cpu", max_len = 30000 )
    test_device_loader = pl.MpDeviceLoader(test_dataloader, device)
    
    optimizer = torch.optim.Adam(model.parameters())
    
    checkpoint_path = Path("checkpoints_spliceAI64_BERT_xla")
    checkpoint_path.mkdir(exist_ok=True)
    
    if False: # restart from last checkpoint
        import glob
        n_epoch = len(glob.glob(checkpoint_path / "*.pt"))
        checkpoint = torch.load(checkpoint_path / ("%i.pt" % (n_epoch-1)))
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
    for epoch in range(100): #  range(n_epoch, n_epoch + 40): 
        np.random.seed(int(time.time())) # does this work? maybe since base dataloader is on CPU? 
        
        xm.master_print('Epoch {} train begin {}'.format(epoch, time.strftime('%l:%M%p %Z on %b %d, %Y')))
    
        train_metrics = one_epoch(
            model, 
            train_device_loader, 
            optimizer = optimizer, 
            device = device
        )
        # TODO: probably need to do something else to get global metrics? 
        xm.master_print(" ".join( [ "%s:%.4g" % (k,v) for k,v in train_metrics.items() ] ) )
    
        np.random.seed(1)
        test_metrics = one_epoch(model, test_dataloader, optimizer = None, device = device, pred_meta_task = True, eval_LM = True)
        xm.master_print(" ".join( [ "%s:%.4g" % (k,v) for k,v in test_metrics.items() ] ) )
        
        to_save = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict()
        }
        to_save.update(train_metrics)
        to_save.update(test_metrics)
        torch.save(to_save, checkpoint_path / ("%i.pt" % epoch))
    xm.wait_device_ops()

xmp.spawn(_mp_fn, args=())
